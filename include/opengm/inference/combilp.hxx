/*
 * combiLP.hxx
 *
 *  Created on: Sep 16, 2013
 *  Author: bsavchyn
 */

#ifndef OPENGM_COMBILP_HXX
#define OPENGM_COMBILP_HXX

// To enable detailed debug output enable the following preprocessor macro:
// #define OPENGM_COMBILP_DEBUG
//
// FIXME: The above macro should be a parameter, maybe?
// FIXME: Downstream code should also consider enabling TRWS_DEBUG_OUTPUT.
//        This is not very intuitive behavior for CombiLP.

#include <boost/scoped_ptr.hpp>

#include <opengm/graphicalmodel/graphicalmodel_manipulator.hxx>
#include <opengm/inference/lpcplex.hxx>
#include <opengm/inference/auxiliary/lp_reparametrization.hxx>
#include <opengm/inference/trws/output_debug_utils.hxx>
#include <opengm/inference/trws/trws_base.hxx>

namespace opengm{

namespace combilp {
	template<class GM>
	void dilateMask(const GM &, typename GM::IndexType, std::vector<bool>&);

	template<class GM>
	void dilateMask(const GM&, std::vector<bool>&);

	template<class GM>
	bool mismatchingLabels(const std::vector<typename GM::LabelType>&,const std::vector<typename GM::LabelType>&, const std::vector<bool>&, std::vector<typename GM::IndexType>&);

	template<class GM>
	bool mismatchingLabelsDense(const GM&, const std::vector<typename GM::LabelType>&, const std::vector<typename GM::LabelType>&, const std::vector<bool>&, std::vector<typename GM::IndexType>&, typename GM::ValueType&);

	template<class GM>
	void getMaskBoundary(const GM&, const std::vector<bool>&, std::vector<bool>&);

	template<class GM>
	GraphicalModelManipulator<GM> maskToManipulator(const GM &, const std::vector<typename GM::LabelType> &, const std::vector<bool> &);
}

template<class LP>
struct CombiLP_ILP_TypeGen
{
	typedef typename GraphicalModelManipulator<
		typename LP::ReparametrizerType::ReparametrizedGMType
	>::MGM
	GraphicalModelType;
};

////////////////////////////////////////////////////////////////////////////////
//
// class CombiLP
//
////////////////////////////////////////////////////////////////////////////////

//
// The LP solver template argument should be an inference algorithm working on
// the original GrahpicalModel GM.
//
// The ILP solver template argument should be an inference algorithm working on
// an auxiliary GraphicalModel. The auxiliary type can be generated by using
// the type generator CombiLP_ILP_TypeGen<LPSOLVER>::GraphicalModelType.
//
// Example usage:
//
// typedef TRWSi<GM, ACC> LPSOLVER;
// typedef typename CombiLP_ILP_TypeGen<LPSOLVER>::GraphicalModelType GM_AUX;
// typedef LPCplex<GM_AUX ,ACC> ILPSOLVER;
//
// typedef CombiLP<GM, ACC, LPSOLVER, ILPSOLVER> Inference;
// Inference inf(gm);
// inf.infer();
// [...]
//

/// \brief CombiLP\n\n
/// Savchynskyy, B. and Kappes, J. H. and Swoboda, P. and Schnoerr, C.:
/// "Global MAP-Optimality by Shrinking the Combinatorial Search Area with Convex Relaxation".
/// In NIPS, 2013.
/// \ingroup inference
template<class GM, class ACC, class LP, class ILP>
class CombiLP : public Inference<GM, ACC>
{
public:
	//
	// Types
	//
	typedef ACC AccumulationType;
	typedef GM GraphicalModelType;
	typedef LP LPSolverType;
	typedef ILP ILPSolverType;
	OPENGM_GM_TYPE_TYPEDEFS;
	typedef std::vector<LabelType> Labeling;

	typedef visitors::VerboseVisitor< CombiLP<GM, ACC, LP, ILP> > VerboseVisitorType;
	typedef visitors::EmptyVisitor< CombiLP<GM, ACC, LP, ILP> > EmptyVisitorType;
	typedef visitors::TimingVisitor< CombiLP<GM, ACC, LP, ILP> > TimingVisitorType;

	typedef typename LPSolverType::ReparametrizerType ReparametrizerType;
	typedef typename ReparametrizerType::ReparametrizedGMType ReparametrizedGMType;
	typedef typename ReparametrizerType::MaskType MaskType;
	typedef GraphicalModelManipulator<ReparametrizedGMType> ManipulatorType;

	struct Parameter
	{
		typedef typename LPSolverType::Parameter LPParameterType;
		typedef typename ILPSolverType::Parameter ILPParameterType;
		typedef typename ReparametrizerType::Parameter RepaParameterType;

		Parameter
		(
			LPParameterType lpsolverParameter = LPParameterType(),
			RepaParameterType repaParameter = RepaParameterType(),
			ILPParameterType ilpsolverParameter = ILPParameterType(),
			size_t maxNumberOfILPCycles = 100,
			bool verbose = false,
			std::string reparametrizedModelFileName = "",
			bool singleReparametrization = true,
			bool saveProblemMasks = false,
			std::string maskFileNamePre = "",
			size_t threads = 1
		)
		: maxNumberOfILPCycles_(maxNumberOfILPCycles)
		, verbose_(verbose)
		, reparametrizedModelFileName_(reparametrizedModelFileName)
		, singleReparametrization_(singleReparametrization)
		, saveProblemMasks_(saveProblemMasks)
		, maskFileNamePre_(maskFileNamePre)
		, threads_(threads)
		{
		}

		size_t maxNumberOfILPCycles_;
		bool verbose_;
		std::string reparametrizedModelFileName_;
		bool singleReparametrization_;
		bool saveProblemMasks_;
		std::string maskFileNamePre_;
		size_t threads_;

		LPParameterType lpsolverParameter_;
		ILPParameterType ilpsolverParameter_;
		RepaParameterType repaParameter_;

#ifdef OPENGM_COMBILP_DEBUG
		void
		print() const
		{
			std::cout << "maxNumberOfILPCycles=" << maxNumberOfILPCycles_ << std::endl;
			std::cout << "verbose" << verbose_ << std::endl;
			std::cout << "reparametrizedModelFileName=" << reparametrizedModelFileName_ << std::endl;
			std::cout << "singleReparametrization=" << singleReparametrization_ << std::endl;
			std::cout << "saveProblemMasks=" << saveProblemMasks_ << std::endl;
			std::cout << "maskFileNamePre=" << maskFileNamePre_ << std::endl;
#ifdef TRWS_DEBUG_OUTPUT
			std::cout << "== lpsolverParameters: ==" << std::endl;
			lpsolverParameter_.print(std::cout);
#endif
		}
#endif
	};

	//
	// Methods
	//
	CombiLP(const GraphicalModelType& gm, const Parameter& param);
	std::string name() const{ return "CombiLP"; }
	const GraphicalModelType& graphicalModel() const { return gm_; }

	InferenceTermination infer();
	template<class VISITOR> InferenceTermination infer(VISITOR&);
	InferenceTermination arg(Labeling &out, const size_t = 1) const;
	ValueType bound() const { return bound_; }
	ValueType value() const { return value_; }

private:
	//
	// Methods
	//
	void performLP();
	template<class VISITOR> InferenceTermination performILP(VISITOR&);

	InferenceTermination inferenceOnSubmodels(const ManipulatorType&, Labeling&, Labeling&) const;
	bool checkOptimality(const ReparametrizedGMType&, const MaskType&, const Labeling&, std::vector<IndexType>&);
	void addNodes(const ReparametrizedGMType&, const std::vector<IndexType>&);

	void debugSaveProblemMasks(size_t, const MaskType&) const;
	void debugSaveProblemMasksMismatches(size_t, const std::vector<IndexType>&) const;

	//
	// Members
	//
	Parameter parameter_;
	GraphicalModelType gm_;
	std::vector<LabelType> labeling_;
	ValueType value_;
	ValueType bound_;
	MaskType mask_;

	// The first phase of CombiLP uses a TRWS solver. For the second phase
	// we need a reparameterizer and the concept is very tightly coupled to
	// the TRWS solver.
	//
	// (TRWS uses a TreeDecompositionStorage and stores unary values. After
	// solving the model, the TreeDecompositionStorage has changed all those
	// values. The reparameterizer reuses all those values.)
	//
	// The current solution is to extract the reparameterizer during the first
	// pass. The problem is that the reparameterizer uses internal pointers to
	// the TRWS structures. So we need to keep the TRWS instance also alive.
	//
	// Sounds complicated...
	//
	// FIXME: Decouple TRWSi and Reparametrizer.
	LPSolverType trwsi_;
	boost::scoped_ptr<ReparametrizerType> reparametrizer_;
};

template<class GM, class ACC, class LP, class ILP>
CombiLP<GM, ACC, LP, ILP>::CombiLP
(
	const GraphicalModelType& gm,
	const Parameter& param
)
: parameter_(param)
, gm_(gm)
, labeling_(gm.numberOfVariables(),std::numeric_limits<LabelType>::max())
, value_(ACC::template neutral<ValueType>())
, bound_(ACC::template ineutral<ValueType>())
, trwsi_(gm_, parameter_.lpsolverParameter_)
, reparametrizer_(trwsi_.getReparametrizer(parameter_.repaParameter_))
{
#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Parameters of the " << name() << " algorithm:" << std::endl;
	param.print();
#endif
};

template<class GM, class ACC, class LP, class ILP>
InferenceTermination
CombiLP<GM, ACC, LP, ILP>::infer()
{
	EmptyVisitorType visitor;
	return infer(visitor);
};

template<class GM, class ACC, class LP, class ILP>
template<class VISITOR>
InferenceTermination
CombiLP<GM, ACC, LP, ILP>::infer
(
	VISITOR &visitor
)
{
	visitor.begin(*this);
	performLP();

	// If all nodes are strict-arc-consistent then we already have calculated
	// the globally optimal solution.
	if ( (visitor(*this) != visitors::VisitorReturnFlag::ContinueInf) ||
	     (std::count(mask_.begin(), mask_.end(), true) == 0) )
	{
		visitor.end(*this);
		return NORMAL;
	}

	InferenceTermination result = performILP(visitor);
	visitor.end(*this);
	return result;
}

template<class GM, class ACC, class LP, class ILP>
InferenceTermination
CombiLP<GM, ACC, LP, ILP>::arg
(
	Labeling& labeling,
	const size_t idx
) const
{
	if (idx != 1)
		return UNKNOWN;

	labeling = labeling_;

	// FIXME: Return the correct inference result.
	return NORMAL;
}

template<class GM, class ACC, class LP, class ILP>
void
CombiLP<GM, ACC, LP, ILP>::performLP()
{
	// FIXME: The TRWSi solver is a class member. See comment in class
	// definition. Obviously it would be better, if we could decouple this.
	LPSolverType &solver = trwsi_;

#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Running LP solver "<< solver.name() << std::endl;
#endif

	solver.infer();
	value_ = solver.value();
	bound_ = solver.bound();
	solver.getTreeAgreement(mask_, &labeling_);

#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Energy of the labeling consistent with the arc consistency =" << gm_.evaluate(labeling_) << std::endl;
	std::cout << "Arc inconsistent set size =" << std::count(mask_.begin(),mask_.end(),false) << std::endl;
	std::cout << "Trivializing." << std::endl;
#endif

	// FIXME?: Why do we reparameterize the model again? The LPSolver already
	// did this. There is no need for instantiating a reparametrizer here, is it?
#ifdef WITH_HDF5
	if (parameter_.reparametrizedModelFileName_.compare("") != 0) {
#ifdef OPENGM_COMBILP_DEBUG
		std::cout << "Saving reparametrized model..." << std::endl;
#endif
		boost::scoped_ptr<ReparametrizerType> reparametrizer(solver.getReparametrizer(parameter_.repaParameter_));
		typename ReparametrizerType::ReparametrizedGMType gm;
		MaskType mask(reparametrizer->graphicalModel().numberOfVariables(), true);
		reparametrizer->reparametrize(&mask);
		reparametrizer->getReparametrizedModel(gm);
		store_into_explicit(gm, parameter_.reparametrizedModelFileName_);
	}
#endif

	// Negate the mask. All non-strict-arc-consistent nodes are now “true”.
	OPENGM_ASSERT_OP(mask_.size(), ==, gm_.numberOfVariables());
	std::transform(mask_.begin(), mask_.end(), mask_.begin(), std::logical_not<bool>());
}

// TODO: Clean this method.
template<class GM, class ACC, class LP, class ILP>
template<class VISITOR>
InferenceTermination
CombiLP<GM, ACC, LP, ILP>::performILP
(
	VISITOR &visitor
)
{
#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Switching to ILP." << std::endl
	          << (parameter_.singleReparametrization_
	             ? "Applying a single uniform reparametrization..."
	             : "Applying reparametrization for each ILP run...")
	          << std::endl;
#endif

	// FIXME: The reparametrizer is a class member. See comment in class
	// definition. Obviously it would be better, if we could decouple this.
	boost::scoped_ptr<ReparametrizerType> &reparametrizer = reparametrizer_;

	// Do not need to dilate the mask in the newer approach.
	// TODO: Throw away non-dense version?
	if (parameter_.singleReparametrization_)
		combilp::dilateMask(gm_, mask_);

	typename ReparametrizerType::ReparametrizedGMType gm;
	bool quitInference = false;
	bool reparametrizedFlag = false; // TODO: Throw away non-dense version?
	InferenceTermination result = TIMEOUT;

	// BEGIN-HACK
	// Target shape for LabelCollapse population of label space.
	std::vector<LabelType> targetShape(gm_.numberOfVariables());
	// END-HACK

	// Main loop for iteration. In each iteration we run the ILP solver on the
	// different subproblems. If the labeling has mismatches compared to the
	// strict-arc-consistent labeling (on the “border”) we grow the ILP
	// subproblem.
	//
	// These steps are repeated as long as the iterationen counter is below the
	// user supplied maximum value and there were any mismatches. If there were
	// no mismatches in the previous iteration we are done and we can just
	// concatenate all the labelings.
	for ( size_t iteration = 0
	    ; !quitInference && iteration < parameter_.maxNumberOfILPCycles_
		; ++iteration )
	{
		// The visitor can tell us to stop. He can also see the gap
		// between value_ (always decreasing) and bound (always increasing). He
		// can either raise a timeout or say that the gap is small enough.
		switch (visitor(*this)) {
		case visitors::VisitorReturnFlag::StopInfBoundReached:
			return CONVERGENCE;
			break;
		case visitors::VisitorReturnFlag::StopInfTimeout:
			// TODO: Should we update intermediate values before quitting?
			return TIMEOUT;
			break;
		default:
			break;
		}

#ifdef OPENGM_COMBILP_DEBUG
		std::cout << "ILP iteration " << iteration << " (size = "
		          << std::count(mask_.begin(), mask_.end(), true)
		          << ")" << std::endl;
#endif

		//
		// Calculates boundary mask.
		//
		MaskType boundaryMask(mask_.size());
		combilp::getMaskBoundary(gm_, mask_, boundaryMask);
		debugSaveProblemMasks(iteration, boundaryMask);

		//
		// Performs reparameterization.
		//
		// The reparametrized flag determines if reparamaterization should be
		// performed. For the non-dense CombiLP we only run reparameterization
		// once and we use a full mask.
		//
		// For Dense CombiLP the reparametrize is wil not be cleared and we
		// run the reparameterization in each iteration but with the updated
		// mask.
		//
		if (!reparametrizedFlag) {
#ifdef OPENGM_COMBILP_DEBUG
			std::cout << "Reparametrizing..." << std::endl;
#endif
			const MaskType fullMask(mask_.size(), true);
			const MaskType *mask = parameter_.singleReparametrization_ ? &fullMask : &mask_;

			reparametrizer->reparametrize(mask);
			reparametrizer->getReparametrizedModel(gm);

			if (parameter_.singleReparametrization_) {
				reparametrizedFlag = true;
			}
		}

		//
		// Splits original model into subproblems using the current mask.
		// Runs MRF inference on each of the subproblems.
		//
		Labeling labeling;
		ManipulatorType manipulator = combilp::maskToManipulator(gm, labeling_, mask_);
		InferenceTermination inf = inferenceOnSubmodels(manipulator, labeling, targetShape);
		if ((inf != NORMAL) && (inf != CONVERGENCE)) {
#ifdef OPENGM_COMBILP_DEBUG
			std::cout << "ILP solver failed to solve the problem. Best attained results will be saved." << std::endl;
#endif
			return inf;
		}

		//
		// Checks for optimality and get list of mismatching labels.
		//
		std::vector<IndexType> mismatches;
		if (checkOptimality(gm, boundaryMask, labeling, mismatches)) {
			quitInference = true;
			labeling_ = labeling;
			value_ = bound_ = gm_.evaluate(labeling_);
			result = NORMAL;
#ifdef OPENGM_COMBILP_DEBUG
			std::cout << "Solved! Optimal energy=" << value() << std::endl;
#endif
		} else {
			debugSaveProblemMasksMismatches(iteration, mismatches);
			addNodes(gm, mismatches);
		}
	}

	return result;
}

template<class GM, class ACC, class LP, class ILP>
InferenceTermination
CombiLP<GM, ACC, LP, ILP>::inferenceOnSubmodels
(
	const ManipulatorType &manipulator,
	Labeling &labeling,
	Labeling &targetShape
) const
{
	std::vector<Labeling> labelings(manipulator.numberOfSubmodels());

	// BEGIN-HACK
	std::cout << "targetShape =";
	for (IndexType i = 0; i < gm_.numberOfVariables(); ++i)
		std::cout << " " << targetShape[i];
	std::cout << std::endl;
	// END-HACK

	for (size_t i = 0; i < manipulator.numberOfSubmodels(); ++i) {
		const typename ManipulatorType::MGM &model = manipulator.getModifiedSubModel(i);
		Labeling &labeling = labelings[i];

		// BEGIN-HACK
		std::vector<LabelType> population(model.numberOfVariables());
		for (IndexType j = 0; j < gm_.numberOfVariables(); ++j) {
			if (manipulator.fixVariable_[j] ||
			    (manipulator.var2subProblem_[j] != i))
			{
				continue;
			}

			population[ manipulator.varMap_[j] ] = targetShape[j];
		}

		std::cout << "population[" << i << "] =";
		for (IndexType j = 0; j < model.numberOfVariables(); ++j)
			std::cout << " " << population[j];
		std::cout << std::endl;
		// END-HACK

		ILPSolverType ilpSolver(model, parameter_.ilpsolverParameter_);
		ilpSolver.populate(population.begin());
		InferenceTermination result = ilpSolver.infer();
		if (result != NORMAL && result != CONVERGENCE)
			return result;

		labeling.resize(model.numberOfVariables());
		ilpSolver.arg(labelings[i]);

		// BEGIN-HACK
		ilpSolver.currentNumberOfLabels(population.begin());
		for (IndexType j = 0; j < gm_.numberOfVariables(); ++j) {
			if (manipulator.fixVariable_[j] ||
			    (manipulator.var2subProblem_[j] != i))
			{
				continue;
			}

			targetShape[j] = population[ manipulator.varMap_[j] ];
		}
		// END-HACK
	}

	manipulator.modifiedSubStates2OriginalState(labelings, labeling);
	return NORMAL;
}

template<class GM, class ACC, class LP, class ILP>
bool
CombiLP<GM, ACC, LP, ILP>::checkOptimality
(
	const ReparametrizedGMType &gm,
	const MaskType &boundaryMask,
	const Labeling &labeling,
	std::vector<IndexType> &mismatches
)
{
#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Boundary size=" << std::count(boundaryMask.begin(),boundaryMask.end(),true) << std::endl;
#endif

	bool isOptimal = false;
	ValueType gap=0;

	//
	// Checks if there are labeling mismatches on border.
	//
	if (parameter_.singleReparametrization_) {
		isOptimal = combilp::mismatchingLabels<GM>(labeling_, labeling, boundaryMask, mismatches);
	} else {
		isOptimal = combilp::mismatchingLabelsDense(gm, labeling_, labeling, mask_, mismatches, gap);
	}

	//
	// Adjust bound. For dense version of CombiLP only.
	//
	if (! parameter_.singleReparametrization_) {
		std::vector<bool> imask = mask_;
		std::transform(imask.begin(), imask.end(), imask.begin(), std::logical_not<bool>());

		ValueType newValue = gm.evaluate(labeling);
		ValueType newBound = gm.evaluate(labeling, mask_)
		                   + gm.evaluate(labeling, imask);

		if (ACC::bop(newValue, value_)) {
			value_ = newValue;
			labeling_ = labeling;
		}

		// for ACC == Minimizer equivalent to: bound_ -= std::min(bound_, newBound)
		ACC::iop(bound_, newBound, bound_);

#ifdef OPENGM_COMBILP_DEBUG
		std::cout << "newvalue=" << newValue << "; best value=" << value_ << std::endl;
		std::cout << "newbound=" << newBound << "; best bound=" << bound_ << std::endl;
		std::cout << "new gap=" << gap << std::endl;
#endif
	}

	// Either no mismatches, or value equals bound.
	return isOptimal || (std::abs(value_ - bound_) <= std::numeric_limits<ValueType>::epsilon() * value_);
}

template<class GM, class ACC, class LP, class ILP>
void
CombiLP<GM, ACC, LP, ILP>::addNodes
(
	const ReparametrizedGMType &gm,
	const std::vector<IndexType> &mismatches
)
{
#ifdef OPENGM_COMBILP_DEBUG
	std::cout << "Adding " << mismatches.size() << " nodes." << std::endl;
#endif
	typedef typename std::vector<IndexType>::const_iterator Iterator;

	// Expand the mask. For the non-dense version we need to add all
	// neighbooring node.
	//
	// For the dense version we just need to flag the specific node.
	for (Iterator it = mismatches.begin(); it != mismatches.end(); ++it) {
		if (parameter_.singleReparametrization_)
			combilp::dilateMask(gm, *it, mask_);
		else
			mask_[*it]=true;
	}
}

template<class GM, class ACC, class LP, class ILP>
void
CombiLP<GM, ACC, LP, ILP>::debugSaveProblemMasks
(
	size_t iteration,
	const MaskType &boundaryMask
) const
{
	// FIXME: The helper functions are only defined if the TRWSi enables
	// them. This is not intuitive behavior for CombiLP.
#if defined(OPENGM_COMBILP_DEBUG) && defined(TRWS_DEBUG_OUTPUT)
	if (parameter_.saveProblemMasks_) {
		std::stringstream s;
		s << parameter_.maskFileNamePre_ << "-mask-"
		  << std::setw(4) << std::setfill('0') << iteration
		  << ".txt";
		OUT::saveContainer(s.str(), mask_.begin(), mask_.end());

		s.str(std::string());
		s << parameter_.maskFileNamePre_ << "-boundaryMask-"
		  << std::setw(4) << std::setfill('0') << iteration
		  << ".txt";
		OUT::saveContainer(s.str(), boundaryMask.begin(), boundaryMask.end());
	}
#endif
}

template<class GM, class ACC, class LP, class ILP>
void
CombiLP<GM, ACC, LP, ILP>::debugSaveProblemMasksMismatches
(
	size_t iteration,
	const std::vector<IndexType> &mismatches
) const
{
	// FIXME: The helper functions are only defined if the TRWSi enables
	// them. This is not intuitive behavior for CombiLP.
#if defined(OPENGM_COMBILP_DEBUG) && defined(TRWS_DEBUG_OUTPUT)
	if (parameter_.saveProblemMasks_) {
		std::stringstream s;
		s << parameter_.maskFileNamePre_ << "-added-"
		  << std::setw(4) << std::setfill('0') << iteration
		  << ".txt";
		OUT::saveContainer(s.str(), mismatches.begin(), mismatches.end());
	}
#endif
}

////////////////////////////////////////////////////////////////////////////////
//
// internal helper functions
//
////////////////////////////////////////////////////////////////////////////////

namespace combilp{

	template<class GM>
	void
	dilateMask
	(
		const GM &gm,
		typename GM::IndexType varId,
		std::vector<bool> &mask
	)
	{
		typedef typename GM::IndexType IndexType;
		typedef typename GM::FactorType FactorType;
		OPENGM_ASSERT_OP(varId, <, gm.numberOfVariables());
		OPENGM_ASSERT_OP(mask.size(), ==, gm.numberOfVariables());

		// Sets all mask for all variables in factor to true.
		typename GM::IndexType numberOfFactors = gm.numberOfFactors(varId);
		for (IndexType i = 0; i < gm.numberOfFactors(varId); ++i) {
			const FactorType &f = gm[ gm.factorOfVariable(varId, i) ];

			for (IndexType j = 0; j < f.numberOfVariables(); ++j)
				mask[ f.variableIndex(j) ] = true;
		}
	}

	template<class GM>
	void
	dilateMask
	(
		const GM &gm,
		std::vector<bool> &mask
	)
	{
		OPENGM_ASSERT_OP(mask.size(), ==, gm.numberOfVariables());
		for (typename GM::IndexType i = 0; i < gm.numberOfVariables(); ++i)
			if (mask[i])
				dilateMask(gm, i, mask);
	}

	// Easier label mismatching for NON-dense version of CombiLP.
	template<class GM>
	bool
	mismatchingLabels
	(
		const std::vector<typename GM::LabelType> &labeling1,
		const std::vector<typename GM::LabelType> &labeling2,
		const std::vector<bool> &mask,
		std::vector<typename GM::IndexType> &result
	)
	{
		OPENGM_ASSERT_OP(labeling1.size(), ==, mask.size());
		OPENGM_ASSERT_OP(labeling2.size(), ==, mask.size());
		result.clear();
		for (typename GM::IndexType varId = 0;varId < mask.size(); ++varId)
			if ((mask[varId]) && (labeling1[varId] != labeling2[varId]))
				result.push_back(varId);
		return result.empty();
	}

	// Label mismatching function used by dense version of CombiLP.
	// TODO: Needs cleanup.
	template<class GM>
	bool
	mismatchingLabelsDense
	(
		const GM &gm,
		const std::vector<typename GM::LabelType> &labeling_out,
		const std::vector<typename GM::LabelType> &labeling_in,
		const std::vector<bool> &mask_in,
		std::vector<typename GM::IndexType> &result,
		typename GM::ValueType& gap
	)
	{
		OPENGM_ASSERT_OP(labeling_in.size(), ==, mask_in.size());
		OPENGM_ASSERT_OP(labeling_out.size(), ==, mask_in.size());
		result.clear();

		//go over all border p/w potentials and check that the corresponding edge 0
		//FIXME: Make types nicer.
		std::vector< std::pair<typename GM::IndexType, typename GM::IndexType> > borderFactors;
		std::vector<typename GM::IndexType> borderFactorCounter(gm.numberOfVariables(),0);//!< is not needed below, just to fit function parameters list
		LPReparametrizer<GM, Minimizer>::getGMMaskBorder(gm, mask_in, &borderFactors, &borderFactorCounter);//!< Minimizer does not play any role in this code, just to instantiate the template

		gap=0;
		std::vector<typename GM::LabelType> ind(2, 0);
		// FIXME: Make types nicer.
		for (typename std::vector<std::pair<typename GM::IndexType,typename GM::IndexType> >::const_iterator fit=borderFactors.begin();
							fit!=borderFactors.end();++fit) {
			typename GM::IndexType var_out=gm[fit->first].variableIndex(fit->second);
			typename GM::IndexType var_in=gm[fit->first].variableIndex(1-fit->second);

			ind[fit->second]=labeling_out[var_out];
			ind[1-fit->second]=labeling_in[var_in];

			if (fabs(gm[fit->first](ind.begin())) > 1e-15)//BSD: improve this line to get an optimal edge and be independent on numerical issues
			{
				gap += gm[fit->first](ind.begin());
				result.push_back(var_out);
			}
		}

		return result.empty();
	}

	template<class GM>
	void
	getMaskBoundary
	(
		const GM &gm,
		const std::vector<bool> &mask,
		std::vector<bool> &boundaryMask
	)
	{
		typedef typename GM::IndexType IndexType;
		typedef typename GM::FactorType FactorType;
		OPENGM_ASSERT_OP(mask.size(), ==, gm.numberOfVariables());

		boundaryMask.assign(mask.size(), false);
		for (IndexType i = 0; i < mask.size(); ++i) {
			if (! mask[i]) continue;

			for (IndexType j = 0; j < gm.numberOfFactors(i); ++j) {
				if (boundaryMask[i]) break;

				typedef typename FactorType::VariablesIteratorType Iter;
				const FactorType& f = gm[ gm.factorOfVariable(i, j) ];
				for (Iter it = f.variableIndicesBegin(); it != f.variableIndicesEnd(); ++it) {
					if (! mask[*it]) {
						boundaryMask[i] = true;
						break;
					}
				}
			}
		}
	}

	template<class GM>
	GraphicalModelManipulator<GM>
	maskToManipulator
	(
		const GM &gm,
		const std::vector<typename GM::LabelType> &labeling,
		const std::vector<bool> &mask
	)
	{
		OPENGM_ASSERT_OP(gm.numberOfVariables(), ==, labeling.size());
		OPENGM_ASSERT_OP(gm.numberOfVariables(), ==, mask.size());
		GraphicalModelManipulator<GM> result(gm, GraphicalModelManipulator<GM>::DROP);

		for (typename GM::IndexType i = 0; i < gm.numberOfVariables(); ++i)
			if (! mask[i])
				result.fixVariable(i, labeling[i]);

		result.lock();
		result.buildModifiedSubModels();
		return result;
	}

} // namespace combilp
} // namespace opengm

#endif
